{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bf68793-6f2b-49da-8736-e7a8a939c8da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6563e660-fabc-4e8c-8214-af63203ac982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Flatten and transform the DataFrame\n",
    "df_transformed = (\n",
    "    brand_data\n",
    "    # Extract _id.$oid as id\n",
    "    .withColumn(\"id\", col(\"_id.$oid\")).drop(\"_id\")\n",
    "    #cpg\":{\"$id\":{\"$oid\":\"601ac114be37ce2ead437550\"},\"$ref\":\"Cogs\"}\n",
    "    # Extract cpg.$id.$oid and cpg.$ref\n",
    "    .withColumn(\"cpg_id\", col(\"cpg.$id.$oid\"))\n",
    "    .withColumn(\"cpg_ref\", col(\"cpg.$ref\"))\n",
    "    .drop(\"cpg\")\n",
    "\n",
    "    # Rename other columns as required (keeping existing ones)\n",
    "    .withColumnRenamed(\"barcode\", \"barcode\")\n",
    "    .withColumnRenamed(\"brandCode\", \"brand_code\")\n",
    "    .withColumnRenamed(\"category\", \"category\")\n",
    "    .withColumnRenamed(\"categoryCode\", \"category_code\")\n",
    "    .withColumnRenamed(\"name\", \"brand_name\")\n",
    "    .withColumnRenamed(\"topBrand\", \"top_brand\")\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b97731f-4302-4bab-bf5d-2689a3d0070e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE brands_table (\n",
    "    id STRING,\n",
    "    barcode STRING,\n",
    "    brand_code STRING,\n",
    "    category STRING,\n",
    "    category_code STRING,\n",
    "    cpg_id STRING,\n",
    "    cpg_ref STRING,\n",
    "    brand_name STRING,\n",
    "    top_brand BOOLEAN\n",
    ")\n",
    "USING DELTA;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60c23c71-f115-40c9-9568-a6d9958bdbcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save DataFrame as a Delta table\n",
    "df_transformed.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"brands_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e42a29ce-fa83-4fc9-9984-95248159b157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "select * from brands_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de9d2d3e-f384-45d6-bdf3-fa50a3ba5588",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_unixtime\n",
    "\n",
    "# Flatten and transform the DataFrame\n",
    "df_transformed = (\n",
    "    users_data\n",
    "    # Extract _id.$oid as id\n",
    "    .withColumn(\"id\", col(\"_id.$oid\")).drop(\"_id\")\n",
    "\n",
    "    # Convert $date timestamps to readable format\n",
    "    .withColumn(\"created_date\", from_unixtime(col(\"createdDate.$date\") / 1000))\n",
    "    .withColumn(\"last_login\", from_unixtime(col(\"lastLogin.$date\") / 1000))\n",
    "    .drop(\"createdDate\", \"lastLogin\")\n",
    "\n",
    "    # Rename other columns as required\n",
    "    .withColumnRenamed(\"role\", \"role\")\n",
    "    .withColumnRenamed(\"signUpSource\", \"sign_up_source\")\n",
    "    .withColumnRenamed(\"state\", \"state\")\n",
    ")\n",
    "\n",
    "# Show the transformed DataFrame\n",
    "#df_transformed.show(truncate=False)\n",
    "\n",
    "display(df_transformed)\n",
    "\n",
    "\n",
    "\n",
    "# Save DataFrame as a Delta table\n",
    "#df_transformed.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"users_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d20412d4-8ff8-4b46-a845-7908f968a1df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE users_table (\n",
    "    id STRING,\n",
    "    active BOOLEAN,\n",
    "    created_date TIMESTAMP,\n",
    "    last_login TIMESTAMP,\n",
    "    role STRING,\n",
    "    sign_up_source STRING,\n",
    "    state STRING\n",
    ")\n",
    "USING DELTA;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8784cccb-62e6-476c-827b-aefe39b2de5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_unixtime, explode\n",
    "\n",
    "# Load JSON file (Update the file path accordingly)\n",
    "\n",
    "df = spark.read.json(f'abfss://recepientjsonfile@kartheekuntdl.dfs.core.windows.net/receipts.json')\n",
    "\n",
    "# Flatten and transform the DataFrame\n",
    "df_transformed = (\n",
    "    df\n",
    "    # Extract _id.$oid as id\n",
    "    .withColumn(\"id\", col(\"_id.$oid\")).drop(\"_id\")\n",
    "\n",
    "    # Convert $date timestamps to readable format\n",
    "    .withColumn(\"created_date\", from_unixtime(col(\"createDate.$date\") / 1000))\n",
    "    .withColumn(\"date_scanned\", from_unixtime(col(\"dateScanned.$date\") / 1000))\n",
    "    .withColumn(\"finished_date\", from_unixtime(col(\"finishedDate.$date\") / 1000))\n",
    "    .withColumn(\"modify_date\", from_unixtime(col(\"modifyDate.$date\") / 1000))\n",
    "    .withColumn(\"points_awarded_date\", from_unixtime(col(\"pointsAwardedDate.$date\") / 1000))\n",
    "    .withColumn(\"purchase_date\", from_unixtime(col(\"purchaseDate.$date\") / 1000))\n",
    "    .drop(\"createDate\", \"dateScanned\", \"finishedDate\", \"modifyDate\", \"pointsAwardedDate\", \"purchaseDate\")\n",
    "\n",
    "    # Rename other columns as required\n",
    "    .withColumnRenamed(\"bonusPointsEarned\", \"bonus_points_earned\")\n",
    "    .withColumnRenamed(\"bonusPointsEarnedReason\", \"bonus_points_reason\")\n",
    "    .withColumnRenamed(\"pointsEarned\", \"points_earned\")\n",
    "    .withColumnRenamed(\"purchasedItemCount\", \"purchased_item_count\")\n",
    "    .withColumnRenamed(\"rewardsReceiptStatus\", \"receipt_status\")\n",
    "    .withColumnRenamed(\"totalSpent\", \"total_spent\")\n",
    "    .withColumnRenamed(\"userId\", \"user_id\")\n",
    ")\n",
    "\n",
    "# Explode the rewardsReceiptItemList to create one row per item\n",
    "df_items = df_transformed.withColumn(\"items\", explode(col(\"rewardsReceiptItemList\"))).drop(\"rewardsReceiptItemList\")\n",
    "\n",
    "# Extract item details from the nested structure\n",
    "df_final = df_items.select(\n",
    "    col(\"id\"),\n",
    "    col(\"created_date\"),\n",
    "    col(\"date_scanned\"),\n",
    "    col(\"finished_date\"),\n",
    "    col(\"modify_date\"),\n",
    "    col(\"points_awarded_date\"),\n",
    "    col(\"purchase_date\"),\n",
    "    col(\"bonus_points_earned\"),\n",
    "    col(\"bonus_points_reason\"),\n",
    "    col(\"points_earned\"),\n",
    "    col(\"purchased_item_count\"),\n",
    "    col(\"receipt_status\"),\n",
    "    col(\"total_spent\"),\n",
    "    col(\"user_id\"),\n",
    "    col(\"items.barcode\").alias(\"item_barcode\"),\n",
    "    col(\"items.description\").alias(\"item_description\"),\n",
    "    col(\"items.finalPrice\").alias(\"item_final_price\"),\n",
    "    col(\"items.itemPrice\").alias(\"item_price\"),\n",
    "    col(\"items.quantityPurchased\").alias(\"item_quantity_purchased\"),\n",
    "    col(\"items.userFlaggedBarcode\").alias(\"item_user_flagged_barcode\"),\n",
    "    col(\"items.userFlaggedPrice\").alias(\"item_user_flagged_price\"),\n",
    "    col(\"items.userFlaggedQuantity\").alias(\"item_user_flagged_quantity\")\n",
    ")\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "display(df_final)\n",
    "\n",
    "# Save DataFrame as a Delta table\n",
    "df_final.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"receipts_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96ea67ad-5cad-45c2-ae28-6e229a1f23b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "Select * from receipts_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c4d0bb4-6f3b-4c0a-8dd9-358ce165e31e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--from the given data in json we are seeing only FLAGGED, FINISHED, REJECTED, PENDING\n",
    "select distinct receipt_status from receipts_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea7b4175-5c79-42ff-bb7c-f4ad029545ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "--5.When considering total number of items purchased from receipts with 'rewardsReceiptStatus’ of ‘Accepted’ or ‘Rejected’, which is greater?\n",
    "with cte as(\n",
    "SELECT receipt_Status, SUM(purchased_item_count) AS total_items_purchased\n",
    "FROM receipts_table\n",
    "WHERE receipt_Status IN ('ACCEPTED', 'REJECTED')\n",
    "GROUP BY receipt_Status)\n",
    "\n",
    "--In order to get the greater value we need to get the max value\n",
    "select * from cte where total_items_purchased == (select max(total_items_purchased) from cte)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf0bea07-0de7-4c6c-bda8-428300fbedce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--6.When considering average spend from receipts with 'rewardsReceiptStatus’ of ‘Accepted’ or ‘Rejected’, which is greater?\n",
    "with cte as (\n",
    "SELECT receipt_Status, avg(total_spent) AS avg_spent\n",
    "FROM receipts_table\n",
    "WHERE receipt_Status IN ('ACCEPTED', 'REJECTED')\n",
    "GROUP BY receipt_Status)\n",
    "--In order to get the greater value we need to get the max value\n",
    "select * from cte where avg_spent == (select max(avg_spent) from cte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3adb904-d882-4dbd-8001-87c70e3041e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--1.What are the top 5 brands by receipts scanned for most recent month?\n",
    "--Here, I dont see any relation between the brands table and receipts table from the files given. I need more information about how these tables are related. The information is incomplete\n",
    "--if i assume barcode in receipt table and barcode in brand table are same then we can get the top 5 brands by receipts scanned for most recent month\n",
    "--the most recent month of date scanned in receipts table is 03 and year is 2021\n",
    "--if you are asking for the top 5 brands by receipts scanned for most recent month then we dont have any records with 03 and year is 2021\n",
    "--Because if i join brands table and receipt table on barcode, i will be having 89 records with 2021 and 01 as latest year and month\n",
    "\n",
    "\n",
    "\n",
    "-- Finding the most recent year and month from receipts table\n",
    "WITH recent_date AS (\n",
    "    SELECT \n",
    "        MAX(YEAR(date_scanned)) AS recent_year,\n",
    "        MAX(MONTH(date_scanned)) AS recent_month\n",
    "    FROM receipts_table\n",
    ")\n",
    "\n",
    "-- Get the top 5 brands by receipts scanned for the most recent month\n",
    "SELECT \n",
    "    b.brand_name, \n",
    "    COUNT(r.id) AS receipts_count\n",
    "FROM \n",
    "    receipts_table r\n",
    "INNER JOIN \n",
    "    brands_table b \n",
    "ON \n",
    "    r.item_barcode = b.barcode\n",
    "INNER JOIN \n",
    "    recent_date rd\n",
    "ON \n",
    "    YEAR(r.date_scanned) = rd.recent_year \n",
    "    AND MONTH(r.date_scanned) = rd.recent_month\n",
    "GROUP BY \n",
    "    b.brand_name\n",
    "ORDER BY \n",
    "    receipts_count DESC\n",
    "LIMIT 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbe12ead-6288-4e05-9901-fb6cb55c21d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--Data Quality issues\n",
    "--users table\n",
    "--1.if we assume id is unique then we can should no have any duplicates for the users\n",
    "--but we are seeing duplicate records for user id and below query can give you those id's and i could see the duplicate records for these id's example id: '5fc961c3b8cfca11a077dd33'\n",
    "\n",
    "-- Select id,count(*) \n",
    "-- from users_table \n",
    "-- group by id \n",
    "-- having count(*) > 1\n",
    "-- order by count(*) desc;\n",
    "\n",
    "--2.we have milliseconds (Unix epoch time) in the date columns and i make sure to be these columns as date using\n",
    "-- (\"created_date\", from_unixtime(col(\"createDate.$date\") / 1000))\n",
    "\n",
    "--Brands_table\n",
    "\n",
    "--here i dont see any any relation between the brands and receipts table as per the json files given\n",
    "--if i can get to know the relation between these tables, we can solve the 2 queries in the above 6 given\n",
    "--Just need relation between these 2 tables\n",
    "\n",
    "--Receipts table\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) Fetch_Assignment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
